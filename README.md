# BigData_pyspark_hadoop
Whats happens when you have petabytes of Data. Think Saprk and Distributed Compute!
This repository has files that utilize spark, MapReduce and distributed compute to transform the large scale data, utilize this scaled data in the sparkML Lib
Guide: https://spark.apache.org/docs/latest/ml-guide.html  
LinkdIn Learning / Big Data Analytics with Hadoop and Apache Spark / Kumaran Ponnambalam
